---
version: "3"

vars:
  cluster:
    sh: | # auto-selects (skip prompt) if there's only one cluster or cluster is already set in the environment or task args
      {{- if eq (index . "cluster") nil -}}
      ls {{.PROJECT_DIR}}/kubernetes/clusters | fzf -1 --height=~5 --prompt="Choose a cluster: " | tr -d '\n\r'
      {{- else -}}
      echo {{index . "cluster"}}
      {{- end -}}

tasks:
  default:
    silent: true
    cmds:
      - task -l

  autovars:
    internal: true
    env: &commonenv
      TALOSCONFIG: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/clusterconfig/talosconfig"
      clusterName: "{{.cluster}}"
    vars:
      node: &nodevar
        sh: |
          {{- if eq (index . "node") nil -}}
          ls {{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/clusterconfig/ | sed 's/.yaml//g' | sed 's/{{.cluster}}-//g' | fzf --height=~10 --prompt="Choose node from cluster {{.cluster}}: "
          {{- else -}}
          echo {{index . "node"}}
          {{- end -}}
      nodes: &nodesvar
        sh: |
          {{- if eq (index . "nodes") nil -}}
          ls {{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/clusterconfig/ | sed 's/.yaml//g' | sed 's/{{.cluster}}-//g' | fzf -m --height=~10 --prompt="Choose nodes from cluster {{.cluster}}: " --print0 | tr '\0' ',' | sed 's/,$//'
          {{- else -}}
          echo {{index . "nodes"}}
          {{- end -}}

  ctl:
    desc: Talosctl wrapper with automatic cluster/node selection (place args after --)
    summary: |
      Runs talosctl with automatic cluster/node selection. 
      Use <TAB> to select multiple nodes.
      example:
        task talos:ctl -- disks
    silent: true
    interactive: true
    requires:
      vars: [cluster]
    vars:
      nodes: *nodesvar
    env: *commonenv
    deps:
      - genconfig
    cmds:
      - talosctl -n {{.nodes}} {{.CLI_ARGS}}

  gensecret:
    desc: Generate talos secrets and store in a new doppler config
    summary: |
      Uses talhelper to generate secrets for a new cluster,
        storing them in a new doppler branch config that branches from "{{.dopplerConfig}}"
      
      This task also uses "{{.dopplerProject}}" for the doppler project.
    prompt: '!!!WARNING!!! This will overwrite any existing secrets for cluster "{{.cluster}}". Continue?'
    interactive: false
    requires:
      vars: [cluster]
    env:
      secretsJson:
        sh: talhelper gensecret | yq '. | tojson'
    vars:
      secretMappings: |
        .cluster.id=CLUSTERID
        .cluster.secret=CLUSTERSECRET
        .trustdinfo.token=TRUSTDINFOTOKEN
        .certs.k8saggregator.crt=K8SAGGREGATORCERT
        .certs.k8saggregatorkey=K8SAGGREGATORCERTKEY
        .certs.k8s.crt=CLUSTERCERT
        .certs.k8s.key=CLUSTERCERTKEY
        .certs.etcd.crt=ETCDCERT
        .certs.etcd.key=ETCDCERTKEY
        .certs.k8sserviceaccount.key=K8SSERVICEACCOUNTKEY
        .certs.os.crt=MACHINECERT
        .certs.os.key=MACHINECERTKEY
        .secrets.bootstraptoken=BOOTSTRAPTOKEN
        .secrets.secretboxencryptionsecret=SECRETBOXENCRYPTIONSECRET
    cmds:
      - for:
          var: secretMappings
        cmd: echo $secretsJson | jq -r '{{index (.ITEM | splitList "=") 0}}' | doppler --silent -p {{.dopplerProject}} -c {{.dopplerConfig}}_{{.cluster}} secrets set {{index (.ITEM | splitList "=") 1 | shellQuote}}
    preconditions:
      - sh: doppler -p {{.dopplerProject}} configs create {{.dopplerConfig}}_{{.cluster}}
        msg: |-
          Failed to create doppler config "{{.dopplerConfig}}_{{.cluster}}" in project "{{.dopplerProject}}". Make sure it doesn't already exist.
        
  genconfig:
    label: 'genconfig-{{.cluster}}'
    desc: Generate talos config
    silent: true
    interactive: true
    dir: "/{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
    env: *commonenv
    requires:
      vars: [cluster, dopplerProject, dopplerConfig]
    sources:
      - talconfig.yaml
      - '*.yaml'
    generates:
      - clusterconfig/*.yaml
      - clusterconfig/talosconfig
    cmds:
      - talhelper -v
      - pwd
      - ls
      - doppler run -p {{.dopplerProject}} -c {{.dopplerConfig}}_{{.cluster}} -- talhelper genconfig

  checkcerts:
    label: "checkcerts-{{.cluster}}"
    desc: Check talos certs
    interactive: true
    requires:
      vars: [cluster, dopplerProject, dopplerConfig]
    dir: "/{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
    env: *commonenv
    vars:
      script: |
        echo "Checking Cluster Cert:"
        echo $CLUSTERCERT | base64 -d | openssl x509 -noout -text
        echo "Checking ETCD Cert:"
        echo $ETCDCERT | base64 -d | openssl x509 -noout -text
        echo "Checking Service Account Key:"
        echo $K8SSERVICEACCOUNTKEY | base64 -d | openssl ec -noout -text
        echo "Checking Machine Cert:"
        echo $MACHINECERT | base64 -d | openssl x509 -noout -text
    cmds:
      - doppler run -p {{.dopplerProject}} -c {{.dopplerConfig}}_{{.cluster}} -- bash -c {{.script | shellQuote}}

  mergeclientconfig:
    desc: Merge cluster talos client config into home directory default talosconfig
    interactive: true
    requires:
      vars: [cluster]
    dir: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
    env: *commonenv
    deps:
      - genconfig
    cmds:
      - talosctl config merge --context={{.cluster}} --talosconfig=$HOME/.talos/config "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/clusterconfig/talosconfig"

  bootstrap:
    desc: Bootstrap talos cluster
    interactive: true
    requires:
      vars: [cluster]
    dir: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
    env: *commonenv
    vars:
      node: *nodevar
    deps:
      - genconfig
    cmds:
      - talosctl bootstrap -n {{.node}}

  disks:
    desc: Get disks insecurely
    interactive: true
    dir: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
    env: *commonenv
    deps:
      - genconfig
    requires:
      vars: [cluster, ip]
    cmds:
      - talosctl -n {{.ip}} disks --insecure

  get-machine:
    desc: Get machine
    interactive: true
    # dir: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
    env: *commonenv
    requires:
      vars: [cluster]
    vars:
      node: *nodevar
    deps:
      - genconfig
    cmds:
      - talosctl -n {{.node}} get mc

  join-node:
    desc: Apply talos config on a new node in maintenance mode
    interactive: true
    # dir: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
    env: *commonenv
    requires:
      vars: [cluster, ip]
    vars:
      node: *nodevar
    deps:
      - genconfig
    cmds:
      - talosctl apply-config --insecure -e {{.ip}} -n {{.ip}} -f "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/clusterconfig/{{.cluster}}-{{.node}}.yaml"
    
  # launch-node-oci:
  #   desc: Launch an Oracle Cloud instance and join it to the cluster
  #   # dir: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
  #   env: *env
  #   interactive: true
  #   requires:
  #     vars: [cluster, node]
  #   vars:
  #     configfile: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/clusterconfig/{{.cluster}}-{{.node}}.yaml"
  #     hostname: "{{.node | splitList \".\" | first}}"
  #     compartmentId:
  #       sh: op read op://{{.opVault}}/Oracle/compartmentId
  #     region:
  #       sh: yq -r '.machine.nodeLabels["topology.kubernetes.io/region"]' "{{.configfile}}"
  #     vcn:
  #       sh: yq -r '.machine.nodeLabels["infra.jtcressy.net/oci-vcn"]' "{{.configfile}}"
  #     shape:
  #       sh: yq -r '.machine.nodeLabels["infra.jtcressy.net/oci-shape"]' "{{.configfile}}"
  #     image:
  #       sh: yq -r '.machine.nodeLabels["infra.jtcressy.net/oci-image"]' "{{.configfile}}"
  #     shapeCpu:
  #       sh: yq -r '.machine.nodeLabels["infra.jtcressy.net/oci-cpus"]' "{{.configfile}}"
  #     shapeMemory:
  #       sh: yq -r '.machine.nodeLabels["infra.jtcressy.net/oci-memory"]' "{{.configfile}}"
  #     vcnId: # use oci cli to get vcn id
  #       sh: oci network vcn list --auth security_token --compartment-id={{.compartmentId | shellQuote}} --query "data[?\"display-name\"=='{{.vcn}}'].id | [0]" --raw-output
  #     subnetId: # use oci cli to get 'default' subnet id
  #       sh: oci network subnet list --auth security_token --compartment-id={{.compartmentId | shellQuote}} --vcn-id={{.vcnId | shellQuote}} --query "data[?\"display-name\"=='default-{{.region}}'].id | [0]" --raw-output
  #     imageId: # use oci cli to get image id of a latest Talos image
  #       sh: oci compute image list --compartment-id={{.compartmentId | shellQuote}} --operating-system Custom --operating-system-version Custom --auth security_token --query "data[?\"display-name\"=='{{.image}}'].id | [0]" --raw-output
  #     availabilityDomain:
  #       sh: oci iam availability-domain list --auth security_token --compartment-id={{.compartmentId | shellQuote}} --query data[0].name --raw-output
  #   cmds:
  #     - |
  #       oci compute instance launch --auth security_token --shape={{.shape | shellQuote}} --shape-config='{"ocpus":{{.shapeCpu}},"memoryInGBs":{{.shapeMemory}}}' --availability-domain={{.availabilityDomain | shellQuote}} --compartment-id={{.compartmentId | shellQuote}} --image-id={{.imageId | shellQuote}} --subnet-id={{.subnetId | shellQuote}} --display-name={{.hostname | shellQuote}} --assign-public-ip=true --launch-options='{"networkType":"PARAVIRTUALIZED"}' --user-data-file={{.configfile}} --query 'data.id' --raw-output
  #       echo ðŸš€ðŸš€ðŸš€
  #   preconditions:
  #     - oci session validate --auth security_token
  #     - |
  #       if [[ $(oci compute instance list --compartment-id={{.compartmentId | shellQuote}} --display-name={{.hostname | shellQuote}} --auth security_token --query "data[?\"lifecycle-state\"!='TERMINATING' && \"lifecycle-state\"!='TERMINATED'].id" --raw-output | wc -l) -gt 0 ]]; then
  #         echo "Instance already exists with display-name {{.hostname}}"
  #         exit 1
  #       else
  #         echo "Instance does not exist with display-name {{.hostname}}. Proceeding with launch. ðŸš€"
  #         exit 0
  #       fi

  # terminate-node-oci:
  #   desc: Terminate an Oracle Cloud instance and remove it from the cluster
  #   # dir: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
  #   env: *env
  #   interactive: true
  #   requires:
  #     vars: [cluster, node]
  #   vars:
  #     configfile: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/clusterconfig/{{.cluster}}-{{.node}}.yaml"
  #     hostname: "{{.node | splitList \".\" | first}}"
  #     compartmentId:
  #       sh: op read op://{{.opVault}}/Oracle/compartmentId
  #     region:
  #       sh: yq -r '.machine.nodeLabels["topology.kubernetes.io/region"]' "{{.configfile}}"
  #     instance:
  #       sh: oci compute instance list --compartment-id={{.compartmentId | shellQuote}} --display-name={{.hostname | shellQuote}} --auth security_token --query "data[?\"lifecycle-state\"!='TERMINATING' && \"lifecycle-state\"!='TERMINATED'].id | [0]" --raw-output
  #   cmds:
  #     - echo {{.instance}}
  #     - talosctl reset -n {{.hostname}}
  #     - oci compute instance --auth security_token terminate --instance-id={{.instance | shellQuote}}
  #   preconditions:
  #     - oci session validate --auth security_token

  apply-config:
    desc: Apply talos config on a node
    summary: |
      args:
        mode: auto, interactive, no-reboot, reboot, staged, try (default: auto)
    interactive: true
    env: *commonenv
    deps:
      - genconfig
    requires:
      vars: [cluster]
    vars:
      nodes: *nodesvar
      mode: '{{ .mode | default "auto" }}'
      dryrun: '{{ .dryrun | default "false" }}'
    cmds:
      - for:
          var: nodes
          split: ','
        cmd: talosctl apply-config -n {{.ITEM}} {{if eq .dryrun "true"}}--dry-run {{end}}-m {{.mode}} -f "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/clusterconfig/{{.cluster}}-{{.ITEM}}.yaml"
    preconditions:
      - talosctl -n {{.node}} get mc

  upgrade-talos:
    desc: Upgrade talos on a node
    interactive: true
    dir: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos"
    env: *commonenv
    requires:
      vars: [cluster, image]
    vars:
      node: *nodevar
      mode: '{{ .mode | default "default"}}' # default or powercycle
      configfile: "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/clusterconfig/{{.cluster}}-{{.node}}.yaml"
      image:
        sh: yq -r '.machine.install.image' "{{.configfile}}"
    deps:
      - genconfig
    cmds:
      - talosctl -n {{.node}} upgrade --image {{.image}} --preserve=true
    preconditions:
      - talosctl -n {{.node}} get mc

  upgrade-k8s:
    desc: Upgrade k8s on a node
    interactive: true
    requires:
      vars: [cluster]
    env: *commonenv
    vars:
      node: *nodevar
      to:
        sh: yq -r '.kubernetesVersion' "{{.PROJECT_DIR}}/kubernetes/clusters/{{.cluster}}/talos/talconfig.yaml"
    deps:
      - genconfig
    cmds:
      - talosctl -n {{.node}} upgrade-k8s --to {{.to}}
    preconditions:
      - talosctl -n {{.node}} get mc